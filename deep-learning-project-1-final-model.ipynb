{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":93057,"databundleVersionId":11145869,"sourceType":"competition"}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# import kagglehub\n# kagglehub.login()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-15T00:56:08.682348Z","iopub.execute_input":"2025-03-15T00:56:08.682646Z","iopub.status.idle":"2025-03-15T00:56:08.692411Z","shell.execute_reply.started":"2025-03-15T00:56:08.682617Z","shell.execute_reply":"2025-03-15T00:56:08.690379Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# deep_learning_spring_2025_project_1_path = kagglehub.competition_download('deep-learning-spring-2025-project-1')\n\n# print('Data source import complete.')\n# from google.colab import drive\n# drive.mount('/content/drive')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T00:56:08.693512Z","iopub.execute_input":"2025-03-15T00:56:08.693848Z","iopub.status.idle":"2025-03-15T00:56:08.715438Z","shell.execute_reply.started":"2025-03-15T00:56:08.693815Z","shell.execute_reply":"2025-03-15T00:56:08.714257Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T00:56:10.422205Z","iopub.execute_input":"2025-03-15T00:56:10.422649Z","iopub.status.idle":"2025-03-15T00:56:10.837058Z","shell.execute_reply.started":"2025-03-15T00:56:10.422609Z","shell.execute_reply":"2025-03-15T00:56:10.835972Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport pickle\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\nfrom torch.utils.data import DataLoader, random_split, TensorDataset\nfrom torch.optim.lr_scheduler import StepLR, MultiStepLR\nfrom PIL import Image\nimport torch.optim.lr_scheduler as lr_scheduler\nimport matplotlib.pyplot as plt\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\ndef load_cifar_batch(file):\n    with open(file, 'rb') as fo:\n        dict = pickle.load(fo, encoding='bytes')\n    return dict\n\n#cifar10_dir = '/content/drive/MyDrive/Data/'\ncifar10_dir = '/kaggle/input/deep-learning-spring-2025-project-1/cifar-10-python/cifar-10-batches-py/'\n\nmeta_data_dict = load_cifar_batch(os.path.join(cifar10_dir, 'batches.meta'))\nlabel_names = [label.decode('utf-8') for label in meta_data_dict[b'label_names']]\n\ntrain_data = []\ntrain_labels = []\nfor i in range(1, 6):\n    batch = load_cifar_batch(os.path.join(cifar10_dir, f'data_batch_{i}'))\n    train_data.append(batch[b'data'])\n    train_labels += batch[b'labels']\n\ntrain_data = np.vstack(train_data).reshape(-1, 3, 32, 32).transpose(0, 2, 3, 1)  # Convert to HWC format\ntrain_labels = np.array(train_labels)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T00:57:33.336496Z","iopub.execute_input":"2025-03-15T00:57:33.336915Z","iopub.status.idle":"2025-03-15T00:57:35.812688Z","shell.execute_reply.started":"2025-03-15T00:57:33.336878Z","shell.execute_reply":"2025-03-15T00:57:35.811510Z"}},"outputs":[{"name":"stdout","text":"Using device: cpu\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"class CustomCIFAR10Dataset(torch.utils.data.Dataset):\n    def __init__(self, images, labels, transform=None):\n        self.images = images\n        self.labels = labels\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.images)\n\n    def __getitem__(self, idx):\n        img = self.images[idx]\n        label = self.labels[idx]\n\n        if self.transform:\n            img = self.transform(img)\n\n        return img, label\n\n\ntest_transform = transforms.Compose([\n    transforms.ToPILImage(),  # Convert numpy array to PIL Image\n    transforms.ToTensor(),\n    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))\n])\n\n# Load test dataset\n#cifar_test_path = '/content/drive/MyDrive/Data/cifar_test_nolabel.pkl'\ncifar_test_path = '/kaggle/input/deep-learning-spring-2025-project-1/cifar_test_nolabel.pkl'\ntest_batch = load_cifar_batch(cifar_test_path)\ntest_images = test_batch[b'data'].astype(np.float32) / 255.0\n\n# Convert test dataset to Tensor\ntest_dataset = [(test_transform(img),) for img in test_images]\ntest_loader = DataLoader(test_dataset, batch_size=256, shuffle=False, num_workers=4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T00:57:37.876055Z","iopub.execute_input":"2025-03-15T00:57:37.876387Z","iopub.status.idle":"2025-03-15T00:57:41.140078Z","shell.execute_reply.started":"2025-03-15T00:57:37.876362Z","shell.execute_reply":"2025-03-15T00:57:41.139068Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.ToPILImage(),\n    #transforms.RandAugment(),  # Automatically applies the best augmentations\n    transforms.RandomHorizontalFlip(),\n    #transforms.RandomRotation(10),\n    transforms.RandomCrop(32, padding=4),\n    transforms.AutoAugment(policy=transforms.AutoAugmentPolicy.CIFAR10),\n    transforms.ToTensor(),\n    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))\n])\n\n# Convert to TensorDataset and apply transformations\n\ntrain_dataset = CustomCIFAR10Dataset(train_data, train_labels, transform=transform)\n\nbatch_test_dict = load_cifar_batch(os.path.join(cifar10_dir, 'test_batch'))\nval_images = batch_test_dict[b'data'].reshape(-1, 3, 32, 32).transpose(0, 2, 3, 1)\nval_labels = np.array(batch_test_dict[b'labels'])\n\nval_dataset = CustomCIFAR10Dataset(val_images, val_labels, transform=test_transform)\n\n# DataLoaders\ntrain_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=4)\nval_loader = DataLoader(val_dataset, batch_size=256, shuffle=False, num_workers=4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T00:57:58.692339Z","iopub.execute_input":"2025-03-15T00:57:58.692671Z","iopub.status.idle":"2025-03-15T00:57:59.166174Z","shell.execute_reply.started":"2025-03-15T00:57:58.692643Z","shell.execute_reply":"2025-03-15T00:57:59.164992Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"class FocalLabelSmoothing(nn.Module):\n    \"\"\"\n    Combines label smoothing with focal loss for better handling of hard examples.\n    \n    Args:\n        classes: Number of classes\n        smoothing: Label smoothing factor\n        gamma: Focal loss power factor\n    \"\"\"\n    def __init__(self, classes=10, smoothing=0.1, gamma=1.0):\n        super(FocalLabelSmoothing, self).__init__()\n        self.confidence = 1.0 - smoothing\n        self.smoothing = smoothing\n        self.classes = classes\n        self.gamma = gamma\n        print(f\"Initialized Focal Label Smoothing with gamma={gamma}\")\n        \n    def forward(self, pred, target):\n        pred = pred.log_softmax(dim=-1)\n        with torch.no_grad():\n            true_dist = torch.zeros_like(pred)\n            true_dist.fill_(self.smoothing / (self.classes - 1))\n            true_dist.scatter_(1, target.unsqueeze(1), self.confidence)\n        \n        pt = torch.exp(pred)  # Probability of true class\n        focal_weight = (1 - pt) ** self.gamma  # Higher weight for hard examples\n        \n        return torch.mean(torch.sum(-true_dist * pred * focal_weight, dim=-1))\n\n# Train function + plot\ndef train_model(model, train_loader, val_loader, epochs=50):\n    criterion = FocalLabelSmoothing(classes=10, smoothing=0.1, gamma=1.0)\n    optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4, nesterov=True)\n    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n\n    train_losses = []\n    val_losses = []\n    train_accuracies = []\n    val_accuracies = []\n    best_val_loss = float('inf')  # Initialize best validation loss\n    best_model_state = None  # Store best model parameters\n    patience = 5  # Define patience threshold\n    patience_counter = 0\n\n    for epoch in range(epochs):\n        # Training Phase\n        model.train()\n        running_loss = 0.0\n        correct = 0\n        total = 0\n        for images, labels in train_loader:\n            images, labels = images.to(device), labels.to(device)\n            optimizer.zero_grad()\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item()\n\n            _, predicted = torch.max(outputs, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n        train_loss = running_loss / len(train_loader)\n        train_acc = 100 * correct / total\n        train_losses.append(train_loss)\n        train_accuracies.append(train_acc)\n\n        # Validation Phase\n        model.eval()\n        val_loss = 0.0\n        correct = 0\n        total = 0\n        with torch.no_grad():\n            for images, labels in val_loader:\n                images, labels = images.to(device), labels.to(device)\n                outputs = model(images)\n                loss = criterion(outputs, labels)\n                val_loss += loss.item()\n\n                _, predicted = torch.max(outputs, 1)\n                total += labels.size(0)\n                correct += (predicted == labels).sum().item()\n\n        val_loss /= len(val_loader)\n        val_acc = 100 * correct / total\n        val_losses.append(val_loss)\n        val_accuracies.append(val_acc)\n\n        scheduler.step()\n        print(f'Epoch {epoch+1}, Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%')\n\n        # # Early Stopping Condition\n        # if val_loss < best_val_loss:\n        #     best_val_loss = val_loss\n        #     patience_counter = 0  # Reset patience counter\n        #     best_model_state = model.state_dict()  # Save the best model\n        # else:\n        #     patience_counter += 1  # Increment counter if no improvement\n        #     print(f\"Early stopping patience: {patience_counter}/{patience}\")\n\n        # if patience_counter >= patience:\n        #     print(\"Early stopping triggered! Restoring best model weights.\")\n        #     model.load_state_dict(best_model_state)  # Restore best model\n        #     break  # Stop training\n\n    # Plot Losses\n    plt.figure(figsize=(10, 5))\n    plt.plot(range(1, epochs + 1), train_losses, label='Train Loss', color='red')\n    plt.plot(range(1, epochs + 1), val_losses, label='Validation Loss', color='blue')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.title('Train Loss & Validation Loss')\n    plt.legend()\n    plt.grid()\n    plt.show()\n\n    # Plot Accuracies\n    plt.figure(figsize=(10, 5))\n    plt.plot(range(1, epochs + 1), train_accuracies, label='Train Accuracy', color='green')\n    plt.plot(range(1, epochs + 1), val_accuracies, label='Validation Accuracy', color='purple')\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy (%)')\n    plt.title('Train Accuracy & Validation Accuracy')\n    plt.legend()\n    plt.grid()\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T00:58:04.719832Z","iopub.execute_input":"2025-03-15T00:58:04.720313Z","iopub.status.idle":"2025-03-15T00:58:04.744171Z","shell.execute_reply.started":"2025-03-15T00:58:04.720268Z","shell.execute_reply":"2025-03-15T00:58:04.742546Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# Define a custom ResNet model from scratch\nclass ResidualBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, stride=1, dropout_rate=0.3):\n        self.dropout_rate = dropout_rate\n        super(ResidualBlock, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.relu = nn.ReLU(inplace=False)\n        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n        self.dropout = nn.Dropout(p=dropout_rate)\n        self.skip = nn.Sequential()\n        if stride != 1 or in_channels != out_channels:\n            self.skip = nn.Sequential(\n                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(out_channels)\n            )\n\n\n    def forward(self, x):\n        identity = x\n        if self.skip:\n            identity = self.skip(x)\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.dropout(out)\n        out += identity\n        # if self.training and torch.rand(1).item() < self.dropout_rate:  # Apply stochastic depth\n        #     out = identity  # Skip block\n        # else:\n        #     out = out + identity  # Regular residual connection\n        out = self.relu(out)\n\n\n        return out\n\nclass CustomResNet(nn.Module):\n    def __init__(self, num_classes=10, dropout_rate=0.3):\n        super(CustomResNet, self).__init__()\n        self.init_conv = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n        self.init_bn = nn.BatchNorm2d(64)\n        self.relu = nn.ReLU(inplace=True)\n        self.layer1 = self._make_layer(64, 64, 4, stride=1)\n        self.layer2 = self._make_layer(64, 110, 3, stride=2)\n        self.layer3 = self._make_layer(110, 180, 2, stride=2)\n        self.layer4 = self._make_layer(180, 300, 2, stride=2)\n        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n        self.dropout = nn.Dropout(p=dropout_rate)\n        self.fc = nn.Linear(300, num_classes)\n\n    def _make_layer(self, in_channels, out_channels, blocks, stride):\n        layers = [ResidualBlock(in_channels, out_channels, stride)]\n        for _ in range(1, blocks):\n            layers.append(ResidualBlock(out_channels, out_channels))\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        out = self.init_conv(x)\n        out = self.init_bn(out)\n        out = self.relu(out)\n        out = self.layer1(out)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        out = self.layer4(out)\n        out = self.avg_pool(out)\n        out = torch.flatten(out, 1)\n        out = self.dropout(out)\n        out = self.fc(out)\n        return out\n\n# put models to devices (CPU/GPU)\nmodel = CustomResNet().to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T00:58:12.478686Z","iopub.execute_input":"2025-03-15T00:58:12.479064Z","iopub.status.idle":"2025-03-15T00:58:12.551812Z","shell.execute_reply.started":"2025-03-15T00:58:12.479035Z","shell.execute_reply":"2025-03-15T00:58:12.550570Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# Print the number of parameters\nfrom torchsummary import summary\nsummary(model, (3, 32, 32))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T00:58:19.117975Z","iopub.execute_input":"2025-03-15T00:58:19.118333Z","iopub.status.idle":"2025-03-15T00:58:19.366380Z","shell.execute_reply.started":"2025-03-15T00:58:19.118306Z","shell.execute_reply":"2025-03-15T00:58:19.365290Z"}},"outputs":[{"name":"stdout","text":"----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Conv2d-1           [-1, 64, 32, 32]           1,728\n       BatchNorm2d-2           [-1, 64, 32, 32]             128\n              ReLU-3           [-1, 64, 32, 32]               0\n            Conv2d-4           [-1, 64, 32, 32]          36,864\n       BatchNorm2d-5           [-1, 64, 32, 32]             128\n              ReLU-6           [-1, 64, 32, 32]               0\n            Conv2d-7           [-1, 64, 32, 32]          36,864\n       BatchNorm2d-8           [-1, 64, 32, 32]             128\n           Dropout-9           [-1, 64, 32, 32]               0\n             ReLU-10           [-1, 64, 32, 32]               0\n    ResidualBlock-11           [-1, 64, 32, 32]               0\n           Conv2d-12           [-1, 64, 32, 32]          36,864\n      BatchNorm2d-13           [-1, 64, 32, 32]             128\n             ReLU-14           [-1, 64, 32, 32]               0\n           Conv2d-15           [-1, 64, 32, 32]          36,864\n      BatchNorm2d-16           [-1, 64, 32, 32]             128\n          Dropout-17           [-1, 64, 32, 32]               0\n             ReLU-18           [-1, 64, 32, 32]               0\n    ResidualBlock-19           [-1, 64, 32, 32]               0\n           Conv2d-20           [-1, 64, 32, 32]          36,864\n      BatchNorm2d-21           [-1, 64, 32, 32]             128\n             ReLU-22           [-1, 64, 32, 32]               0\n           Conv2d-23           [-1, 64, 32, 32]          36,864\n      BatchNorm2d-24           [-1, 64, 32, 32]             128\n          Dropout-25           [-1, 64, 32, 32]               0\n             ReLU-26           [-1, 64, 32, 32]               0\n    ResidualBlock-27           [-1, 64, 32, 32]               0\n           Conv2d-28           [-1, 64, 32, 32]          36,864\n      BatchNorm2d-29           [-1, 64, 32, 32]             128\n             ReLU-30           [-1, 64, 32, 32]               0\n           Conv2d-31           [-1, 64, 32, 32]          36,864\n      BatchNorm2d-32           [-1, 64, 32, 32]             128\n          Dropout-33           [-1, 64, 32, 32]               0\n             ReLU-34           [-1, 64, 32, 32]               0\n    ResidualBlock-35           [-1, 64, 32, 32]               0\n           Conv2d-36          [-1, 110, 16, 16]           7,040\n      BatchNorm2d-37          [-1, 110, 16, 16]             220\n           Conv2d-38          [-1, 110, 16, 16]          63,360\n      BatchNorm2d-39          [-1, 110, 16, 16]             220\n             ReLU-40          [-1, 110, 16, 16]               0\n           Conv2d-41          [-1, 110, 16, 16]         108,900\n      BatchNorm2d-42          [-1, 110, 16, 16]             220\n          Dropout-43          [-1, 110, 16, 16]               0\n             ReLU-44          [-1, 110, 16, 16]               0\n    ResidualBlock-45          [-1, 110, 16, 16]               0\n           Conv2d-46          [-1, 110, 16, 16]         108,900\n      BatchNorm2d-47          [-1, 110, 16, 16]             220\n             ReLU-48          [-1, 110, 16, 16]               0\n           Conv2d-49          [-1, 110, 16, 16]         108,900\n      BatchNorm2d-50          [-1, 110, 16, 16]             220\n          Dropout-51          [-1, 110, 16, 16]               0\n             ReLU-52          [-1, 110, 16, 16]               0\n    ResidualBlock-53          [-1, 110, 16, 16]               0\n           Conv2d-54          [-1, 110, 16, 16]         108,900\n      BatchNorm2d-55          [-1, 110, 16, 16]             220\n             ReLU-56          [-1, 110, 16, 16]               0\n           Conv2d-57          [-1, 110, 16, 16]         108,900\n      BatchNorm2d-58          [-1, 110, 16, 16]             220\n          Dropout-59          [-1, 110, 16, 16]               0\n             ReLU-60          [-1, 110, 16, 16]               0\n    ResidualBlock-61          [-1, 110, 16, 16]               0\n           Conv2d-62            [-1, 180, 8, 8]          19,800\n      BatchNorm2d-63            [-1, 180, 8, 8]             360\n           Conv2d-64            [-1, 180, 8, 8]         178,200\n      BatchNorm2d-65            [-1, 180, 8, 8]             360\n             ReLU-66            [-1, 180, 8, 8]               0\n           Conv2d-67            [-1, 180, 8, 8]         291,600\n      BatchNorm2d-68            [-1, 180, 8, 8]             360\n          Dropout-69            [-1, 180, 8, 8]               0\n             ReLU-70            [-1, 180, 8, 8]               0\n    ResidualBlock-71            [-1, 180, 8, 8]               0\n           Conv2d-72            [-1, 180, 8, 8]         291,600\n      BatchNorm2d-73            [-1, 180, 8, 8]             360\n             ReLU-74            [-1, 180, 8, 8]               0\n           Conv2d-75            [-1, 180, 8, 8]         291,600\n      BatchNorm2d-76            [-1, 180, 8, 8]             360\n          Dropout-77            [-1, 180, 8, 8]               0\n             ReLU-78            [-1, 180, 8, 8]               0\n    ResidualBlock-79            [-1, 180, 8, 8]               0\n           Conv2d-80            [-1, 300, 4, 4]          54,000\n      BatchNorm2d-81            [-1, 300, 4, 4]             600\n           Conv2d-82            [-1, 300, 4, 4]         486,000\n      BatchNorm2d-83            [-1, 300, 4, 4]             600\n             ReLU-84            [-1, 300, 4, 4]               0\n           Conv2d-85            [-1, 300, 4, 4]         810,000\n      BatchNorm2d-86            [-1, 300, 4, 4]             600\n          Dropout-87            [-1, 300, 4, 4]               0\n             ReLU-88            [-1, 300, 4, 4]               0\n    ResidualBlock-89            [-1, 300, 4, 4]               0\n           Conv2d-90            [-1, 300, 4, 4]         810,000\n      BatchNorm2d-91            [-1, 300, 4, 4]             600\n             ReLU-92            [-1, 300, 4, 4]               0\n           Conv2d-93            [-1, 300, 4, 4]         810,000\n      BatchNorm2d-94            [-1, 300, 4, 4]             600\n          Dropout-95            [-1, 300, 4, 4]               0\n             ReLU-96            [-1, 300, 4, 4]               0\n    ResidualBlock-97            [-1, 300, 4, 4]               0\nAdaptiveAvgPool2d-98            [-1, 300, 1, 1]               0\n          Dropout-99                  [-1, 300]               0\n          Linear-100                   [-1, 10]           3,010\n================================================================\nTotal params: 4,964,842\nTrainable params: 4,964,842\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 0.01\nForward/backward pass size (MB): 25.33\nParams size (MB): 18.94\nEstimated Total Size (MB): 44.28\n----------------------------------------------------------------\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# Train the model\ntrain_model(model, train_loader, val_loader, epochs=100) #change epoch\n\n# Generate submission file\nmodel.eval()\npredictions = []\nwith torch.no_grad():\n    for batch in test_loader:\n        images = batch[0].to(device)  # Get images tensor from tuple and move to device\n        outputs = model(images)\n        _, predicted = torch.max(outputs, 1)\n        predictions.extend(predicted.cpu().numpy())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T01:03:46.464440Z","iopub.execute_input":"2025-03-15T01:03:46.464813Z","iopub.status.idle":"2025-03-15T01:03:46.469413Z","shell.execute_reply.started":"2025-03-15T01:03:46.464782Z","shell.execute_reply":"2025-03-15T01:03:46.468109Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"# Generate submission file\nsubmission = pd.DataFrame({'ID': np.arange(len(predictions)), 'Labels': predictions})\nsubmission.to_csv('/kaggle/working/submission_1_4.csv', index=False)\ntorch.save(model, '/kaggle/working/submission_1_4.pth')\nprint(\"Submission1 file saved.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}